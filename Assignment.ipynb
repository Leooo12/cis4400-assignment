{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9670fd34",
   "metadata": {},
   "source": [
    "# Assignment \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b509c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('air_quality.csv', <http.client.HTTPMessage at 0x7fe139d1dc60>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assignment 1 Data Sourcing\n",
    "import urllib.request\n",
    "\n",
    "# URL of the CSV file to download\n",
    "url = 'https://data.cityofnewyork.us/api/views/c3uy-2p5r/rows.csv?accessType=DOWNLOAD'\n",
    "\n",
    "# Name of the local file to save the downloaded CSV file\n",
    "filename = 'air_quality.csv'\n",
    "\n",
    "# Download the CSV file from the URL and save it to the local file\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd9d3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_quality.csv uploaded to S3 bucket cis4400assignment with key air_quality.csv\n"
     ]
    }
   ],
   "source": [
    "#Assignment 1 Storage - Amazon S3\n",
    "import boto3\n",
    "\n",
    "# AWS credentials\n",
    "ACCESS_KEY = 'AKIAYPOUV7HYUJGI5K7M'\n",
    "SECRET_KEY = '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'\n",
    "\n",
    "# Name of the S3 bucket to upload the CSV file to\n",
    "BUCKET_NAME = 'cis4400assignment'\n",
    "\n",
    "# Name of the local file to upload\n",
    "filename = 'air_quality.csv'\n",
    "\n",
    "# S3 key to use for the uploaded file (can be the same as filename)\n",
    "s3_key = 'air_quality.csv'\n",
    "\n",
    "# Create an S3 client using the AWS credentials\n",
    "s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)\n",
    "\n",
    "# Upload the local file to the S3 bucket\n",
    "s3.upload_file(filename, BUCKET_NAME, s3_key)\n",
    "\n",
    "print(f'{filename} uploaded to S3 bucket {BUCKET_NAME} with key {s3_key}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1 update dataset annuarly\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import datetime\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Set the URL for the dataset\n",
    "url = \"https://data.cityofnewyork.us/api/views/c3uy-2p5r/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    "# Set the name of the file to save the dataset\n",
    "filename = \"airquality.csv\"\n",
    "\n",
    "def update_dataset():\n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(filename):\n",
    "        # If the file exists, get the modification time\n",
    "        mtime = os.path.getmtime(filename)\n",
    "        # Convert the modification time to a datetime object\n",
    "        mtime_dt = datetime.datetime.fromtimestamp(mtime)\n",
    "        # Get the current year\n",
    "        current_year = datetime.datetime.now().year\n",
    "        # Check if the file was last modified in the current year\n",
    "        if mtime_dt.year == current_year:\n",
    "            # If the file was last modified in the current year, exit the function\n",
    "            print(\"Dataset is up-to-date.\")\n",
    "            return\n",
    "\n",
    "    # Download the dataset\n",
    "    response = requests.get(url)\n",
    "    # Save the dataset to a file\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Load the dataset into a pandas DataFrame\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Perform any necessary data processing here\n",
    "\n",
    "    # Save the updated dataset to the same file\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "# Schedule the update function to run annually on January 1st at midnight\n",
    "schedule.every().day.at(\"00:00\").do(update_dataset).tag('update')\n",
    "\n",
    "# Run the scheduled tasks\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12fcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
